{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tangent: Source-to-Source Debuggable Derivatives",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cksac/colab/blob/master/Tangent_Source_to_Source_Debuggable_Derivatives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B17qq0kVAos0",
        "colab_type": "text"
      },
      "source": [
        "# Tangent\n",
        "\n",
        "* [Announcement](https://research.googleblog.com/2017/11/tangent-source-to-source-debuggable.html)\n",
        "* [Github repo](https://github.com/google/tangent)\n",
        "\n",
        "This notebook is just the examples from the `README` in executable form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRDA2Dy2Ayhc",
        "colab_type": "text"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We need to install `tangent` and any dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBTm9yG0Aj4r",
        "colab_type": "code",
        "outputId": "98f6fef4-ac67-4828-9b0f-8e100d01cba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "!pip install tangent"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tangent\n",
            "  Downloading tangent-0.1.9.tar.gz (80kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hCollecting astor>=0.6 (from tangent)\n",
            "  Downloading astor-0.6.2-py2.py3-none-any.whl\n",
            "Collecting autograd>=1.2 (from tangent)\n",
            "  Downloading autograd-1.2.tar.gz\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (from tangent)\n",
            "Requirement already satisfied: future in /usr/local/lib/python2.7/dist-packages (from tangent)\n",
            "Collecting gast (from tangent)\n",
            "  Downloading gast-0.2.0.tar.gz\n",
            "Collecting nose (from tangent)\n",
            "  Downloading nose-1.3.7-py2-none-any.whl (154kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from tangent)\n",
            "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from tangent)\n",
            "Collecting tf-nightly>=1.5.0.dev20171026 (from tangent)\n",
            "  Downloading tf_nightly-1.6.0.dev20180130-cp27-cp27mu-manylinux1_x86_64.whl (44.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 44.7MB 26kB/s \n",
            "\u001b[?25hRequirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python2.7/dist-packages (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Collecting absl-py>=0.1.6 (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "  Downloading absl-py-0.1.9.tar.gz (79kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Collecting tb-nightly<1.6.0a0,>=1.5.0a0 (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "  Downloading tb_nightly-1.5.0a20180130-py2-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 364kB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0 (from tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "  Downloading termcolor-1.1.0.tar.gz\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python2.7/dist-packages (from protobuf>=3.4.0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: futures>=3.1.1; python_version < \"3.2\" in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.6.0a0,>=1.5.0a0->tf-nightly>=1.5.0.dev20171026->tangent)\n",
            "Building wheels for collected packages: tangent, autograd, gast, absl-py, termcolor\n",
            "  Running setup.py bdist_wheel for tangent ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/f0/ae/c2/5b094a427f1a1b31c32b94df26678b3efcfe7fedddd2ab4181\n",
            "  Running setup.py bdist_wheel for autograd ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/ea/d4/2d/e7d74fb5d727853026c54f23fa96f0b8defefc7d57dcaca0aa\n",
            "  Running setup.py bdist_wheel for gast ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/8e/fa/d6/77dd17d18ea23fd7b860e02623d27c1be451521af40dd4a13e\n",
            "  Running setup.py bdist_wheel for absl-py ... \u001b[?25l-"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b \bdone\r\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/04/f5/7c/5d4eab10ddf87dec875016e74ba289d87270a90fb2662a76fc\n",
            "  Running setup.py bdist_wheel for termcolor ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/de/f7/bf/1bcac7bf30549e6a4957382e2ecab04c88e513117207067b03\n",
            "Successfully built tangent autograd gast absl-py termcolor\n",
            "Installing collected packages: astor, autograd, gast, nose, absl-py, tb-nightly, termcolor, tf-nightly, tangent\n",
            "Successfully installed absl-py-0.1.9 astor-0.6.2 autograd-1.2 gast-0.2.0 nose-1.3.7 tangent-0.1.9 tb-nightly-1.5.0a20180130 termcolor-1.1.0 tf-nightly-1.6.0.dev20180130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thnwgOq2BCu0",
        "colab_type": "text"
      },
      "source": [
        "# Basic examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn-S2rK2A4zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  a = x * x\n",
        "  b = x * a\n",
        "  c = a + b\n",
        "  return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQsIIDVfBTjF",
        "colab_type": "code",
        "outputId": "9c2f6270-1fc3-4aa7-dc8a-bd5e2c9f59d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f(3.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2u0NUjaBQ-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tangent\n",
        "df = tangent.grad(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MENbIeqWGlXv",
        "colab_type": "code",
        "outputId": "0c4ed3b3-710a-4517-cb27-3e4e9ef8c67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df(3.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv_vkEIyBeXU",
        "colab_type": "text"
      },
      "source": [
        "Re-executing the cell below will also show the source for `df`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5WnjbB4BX1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIuV3gPWKr6",
        "colab_type": "text"
      },
      "source": [
        "## Tangent and TF Eager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5-NT9ShBYx8",
        "colab_type": "code",
        "outputId": "6f4d1964-2496-442e-8eef-95a4bd800eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import tangent\n",
        "import tensorflow as tf\n",
        "\n",
        "def f(W,x):\n",
        "  h1 = tf.matmul(x,W)\n",
        "  h2 = tf.tanh(h1)\n",
        "  out = tf.reduce_sum(h2)\n",
        "  return out\n",
        "\n",
        "dfdW = tangent.grad(f, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdW(W, x, bout=1.0):\n",
            "    h1 = tf.matmul(x, W)\n",
            "    h2 = tf.tanh(h1)\n",
            "    out = tf.reduce_sum(h2)\n",
            "    assert tangent.shapes_match(out, bout\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(out), numpy.shape(bout))\n",
            "\n",
            "    # Grad of: out = tf.reduce_sum(h2)\n",
            "    _bh2 = tangent.unreduce(bout, tangent.shape_as_list(h2), None, False)\n",
            "    bh2 = _bh2\n",
            "\n",
            "    # Grad of: h2 = tf.tanh(h1)\n",
            "    _h2 = h2\n",
            "    _bh1 = bh2 * (1 - _h2 * _h2)\n",
            "    bh1 = _bh1\n",
            "\n",
            "    # Grad of: h1 = tf.matmul(x, W)\n",
            "    _bW = tangent.matmul_adjoint_y(bh1, x, W, False, False)\n",
            "    bW = _bW\n",
            "    return bW\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhR5qf1IWOOC",
        "colab_type": "text"
      },
      "source": [
        "## Tangent and subroutines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSj2LD7vGM4N",
        "colab_type": "code",
        "outputId": "7de214c7-24d1-4551-ddca-bc08dc187992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "def f(x):\n",
        "  a = _mul(x, x)\n",
        "  return a\n",
        "\n",
        "def _mul(x, y):\n",
        "  out = x * y\n",
        "  return out\n",
        "\n",
        "import tangent\n",
        "tangent.grad(f, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdx(x, ba=1.0):\n",
            "    # Initialize the tape\n",
            "    _stack = tangent.Stack()\n",
            "    _substack = tangent.Stack()\n",
            "    tangent.push_stack(_stack, _substack, '_d5d22c0d')\n",
            "    a = pri__mulxy(_substack, x, x)\n",
            "    assert tangent.shapes_match(a, ba\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(a), numpy.shape(ba))\n",
            "\n",
            "    # Grad of: a = _mul(x, x)\n",
            "    _substack = tangent.pop_stack(_stack, '_d5d22c0d')\n",
            "    dxs = _d_muldxy(_substack, ba, x, x)\n",
            "    _bx = dxs[0]\n",
            "    _bx2 = dxs[1]\n",
            "    bx = _bx\n",
            "    bx = tangent.add_grad(bx, _bx2)\n",
            "    return bx\n",
            "\n",
            "\n",
            "def pri__mulxy(_stack, x, y):\n",
            "    out = x * y\n",
            "    result = out\n",
            "    tangent.push(_stack, result, '_a1151cb1')\n",
            "    return out\n",
            "\n",
            "\n",
            "def _d_muldxy(_stack, bout, x, y):\n",
            "    result = tangent.pop(_stack, '_a1151cb1')\n",
            "\n",
            "    # Grad of: out = x * y\n",
            "    _bx = tangent.unbroadcast(bout * y, x)\n",
            "    _by = tangent.unbroadcast(bout * x, y)\n",
            "    bx = _bx\n",
            "    by = _by\n",
            "    return bx, by, result\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tangent_21c9.dfdx>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkWlFbiXXD0S",
        "colab_type": "text"
      },
      "source": [
        "## Tangent and Control Flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDiCpHxoW17T",
        "colab_type": "code",
        "outputId": "846d6dce-f93d-476c-93cc-44dc74aff8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "def f(x):\n",
        "  if x > 0:\n",
        "    a = x ** 2.0\n",
        "  else:\n",
        "    a = -x\n",
        "  out = a * a\n",
        "  return out\n",
        "\n",
        "tangent.grad(f, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdx(x, bout=1.0):\n",
            "    # Initialize the tape\n",
            "    _stack = tangent.Stack()\n",
            "\n",
            "    # Beginning of forward pass\n",
            "    cond = x > 0\n",
            "    if cond:\n",
            "        a = x ** 2.0\n",
            "    else:\n",
            "        a = -x\n",
            "    tangent.push(_stack, cond, '_086298b7')\n",
            "    out = a * a\n",
            "    assert tangent.shapes_match(out, bout\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(out), numpy.shape(bout))\n",
            "\n",
            "    # Grad of: out = a * a\n",
            "    _ba = tangent.unbroadcast(bout * a, a)\n",
            "    _ba2 = tangent.unbroadcast(bout * a, a)\n",
            "    ba = _ba\n",
            "    ba = tangent.add_grad(ba, _ba2)\n",
            "    cond = tangent.pop(_stack, '_086298b7')\n",
            "    if cond:\n",
            "        # Grad of: a = x ** 2.0\n",
            "        _bx = 2.0 * x * ba\n",
            "        bx = _bx\n",
            "    else:\n",
            "        # Grad of: a = -x\n",
            "        _bx2 = -ba\n",
            "        bx = _bx2\n",
            "    return bx\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tangent_961c.dfdx>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgIICA5IXR6a",
        "colab_type": "text"
      },
      "source": [
        "## Tangent and loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc01frTVXYTa",
        "colab_type": "code",
        "outputId": "f24fc737-f7f9-49a0-b7b6-da5b2f782453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "def f(x):\n",
        "  for i in range(3):\n",
        "    x = x ** 0.5\n",
        "  return x\n",
        "\n",
        "tangent.grad(f, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdx(x, bx=1.0):\n",
            "    # Initialize the tape\n",
            "    _stack = tangent.Stack()\n",
            "\n",
            "    # Beginning of forward pass\n",
            "    i2 = 0\n",
            "    for i in range(3):\n",
            "        i2 += 1\n",
            "        tangent.push(_stack, x, '_4e4bfb98')\n",
            "        x = x ** 0.5\n",
            "    tangent.push(_stack, i2, '_cffbe358')\n",
            "    assert tangent.shapes_match(x, bx\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(x), numpy.shape(bx))\n",
            "\n",
            "    # Beginning of backward pass\n",
            "    i2 = tangent.pop(_stack, '_cffbe358')\n",
            "    for _ in range(i2):\n",
            "        # Grad of: x = x ** 0.5\n",
            "        _x = x\n",
            "        x = tangent.pop(_stack, '_4e4bfb98')\n",
            "        _bx = 0.5 * x ** -0.5 * bx\n",
            "        bx = tangent.init_grad(x, allow_lazy_initializer=True)\n",
            "        bx = tangent.add_grad(bx, _bx)\n",
            "    return bx\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tangent_61cd.dfdx>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeuonBTBXjXT",
        "colab_type": "text"
      },
      "source": [
        "# Tangent and Debugging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRmDQk9iXgB7",
        "colab_type": "code",
        "outputId": "84908126-9e17-4303-b367-305807252d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "import tangent\n",
        "import pdb\n",
        "\n",
        "def f(x):\n",
        "  a = x * x\n",
        "  b = x * a\n",
        "  c = a + b\n",
        "  \n",
        "  pdb.set_trace()\n",
        "  return c\n",
        "\n",
        "tangent.grad(f, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdx(x, bc=1.0):\n",
            "    a = x * x\n",
            "    b = x * a\n",
            "    c = a + b\n",
            "    pdb.set_trace()\n",
            "    assert tangent.shapes_match(c, bc\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(c), numpy.shape(bc))\n",
            "\n",
            "    # Grad of: c = a + b\n",
            "    _ba2 = tangent.unbroadcast(bc, a)\n",
            "    _bb = tangent.unbroadcast(bc, b)\n",
            "    ba = _ba2\n",
            "    bb = _bb\n",
            "\n",
            "    # Grad of: b = x * a\n",
            "    _bx3 = tangent.unbroadcast(bb * a, x)\n",
            "    _ba = tangent.unbroadcast(bb * x, a)\n",
            "    bx = _bx3\n",
            "    ba = tangent.add_grad(ba, _ba)\n",
            "\n",
            "    # Grad of: a = x * x\n",
            "    _bx = tangent.unbroadcast(ba * x, x)\n",
            "    _bx2 = tangent.unbroadcast(ba * x, x)\n",
            "    bx = tangent.add_grad(bx, _bx)\n",
            "    bx = tangent.add_grad(bx, _bx2)\n",
            "    return bx\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tangent_29d7.dfdx>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IAp6w9hXxo5",
        "colab_type": "code",
        "outputId": "c3f8ad15-862f-4cbb-a046-f4ce6f4d17ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "def f(x):\n",
        "  a = x * x\n",
        "  with tangent.insert_grad_of(x) as dx:\n",
        "    print(\"dc/dx = %2.2f\" % dx)\n",
        "    pdb.set_trace()\n",
        "  b = x * a\n",
        "  c = a + b\n",
        "  \n",
        "  return c\n",
        "\n",
        "tangent.grad(f, verbose=True)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def dfdx(x, bc=1.0):\n",
            "    a = x * x\n",
            "    b = x * a\n",
            "    c = a + b\n",
            "    assert tangent.shapes_match(c, bc\n",
            "        ), 'Shape mismatch between return value (%s) and seed derivative (%s)' % (\n",
            "        numpy.shape(c), numpy.shape(bc))\n",
            "\n",
            "    # Grad of: c = a + b\n",
            "    _ba2 = tangent.unbroadcast(bc, a)\n",
            "    _bb = tangent.unbroadcast(bc, b)\n",
            "    ba = _ba2\n",
            "    bb = _bb\n",
            "\n",
            "    # Grad of: b = x * a\n",
            "    _bx3 = tangent.unbroadcast(bb * a, x)\n",
            "    _ba = tangent.unbroadcast(bb * x, a)\n",
            "    bx = _bx3\n",
            "    ba = tangent.add_grad(ba, _ba)\n",
            "\n",
            "    # Inserted code\n",
            "    print 'dc/dx = %2.2f' % bx\n",
            "    pdb.set_trace()\n",
            "\n",
            "    # Grad of: a = x * x\n",
            "    _bx = tangent.unbroadcast(ba * x, x)\n",
            "    _bx2 = tangent.unbroadcast(ba * x, x)\n",
            "    bx = tangent.add_grad(bx, _bx)\n",
            "    bx = tangent.add_grad(bx, _bx2)\n",
            "    return bx\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tangent_9535.dfdx>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnYAQysbYtM6",
        "colab_type": "text"
      },
      "source": [
        "# Forward mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1veLyZjRYPp5",
        "colab_type": "code",
        "outputId": "6656d48a-e24a-479c-f80a-9b0ed32ddf90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import tangent\n",
        "\n",
        "def f(x):\n",
        "  a = x * x\n",
        "  b = x * a\n",
        "  c = a + b\n",
        "  return c\n",
        "\n",
        "forward_df = tangent.jvp(f, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def _tftx(x, dx):\n",
            "    if not tangent.shapes_match(x, dx):\n",
            "        raise ValueError(\n",
            "            'Shape mismatch between argument value (%s) and seed derivative (%s)'\n",
            "             % (numpy.shape(x), numpy.shape(dx)))\n",
            "\n",
            "    # Primal and tangent of: a = x * x\n",
            "    tmp = x * x\n",
            "    da = dx * x + x * dx\n",
            "    a = tmp\n",
            "\n",
            "    # Primal and tangent of: b = x * a\n",
            "    db = dx * a + x * da\n",
            "\n",
            "    # Primal and tangent of: c = a + b\n",
            "    dc = da + db\n",
            "    return dc\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}